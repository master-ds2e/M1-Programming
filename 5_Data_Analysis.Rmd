<style>
div.python pre { background-color: #fdfcff; }
</style>

<style>
div.r pre { background-color: #fffffc; }
</style>

http://eric.univ-lyon2.fr/~ricco/tanagra/fichiers/fr_Tanagra_R_Python_Data_Perfs.pdf
https://juba.github.io/tidyverse/06-tidyverse.html
http://python-simple.com/python-pandas/panda-intro.php

"It is often said that 80% of data analysis is spent on the process of cleaning and preparing the data (Dasu and Johnson 2003).  Data preparation is not just a first step,  but must berepeated many times over the course of analysis as new problems come to light or new datais collected." [(Wickham, 2014)](https://www.jstatsoft.org/article/view/v059i10).
Data can be store as csv, txt, excel format, etc.. There is a lot of different ways of storing data as seen in other lessons this semester. here We will focus on using data from txt or csv format for simplicity, csv are just delimited text file with comma.
We need to be able to open and treat data whatever the type of data that we are dealing with, sometimes it's easier to transform data in a way that we are use to work with. Sometimes it's unapropriate and you can corrupt or miss information in the data base, it's important to read documentation if you are in front of a new data formating type. 


# R


The Tidyverse is a collection of differents packages which works together in a common philosophy, the biggest contributor to this collection is named Hadley Wickham. Hadley Wickham did so much for the R community, he published a lot of books  that I highly recommend to read. Check [Wikipedia: Haldey Wickham](https://en.wikipedia.org/wiki/Hadley_Wickham) for his bibliograpy. Here is the list of libraries that are contained in the Tidyverse:
- ggplot2: Visualization
- dplyr: Data manipulation
- tidyr: Data formatting
- purrr: programming
- readr: Data importation
- tibble: Data tables
- forcats: Qualitative variables
- stringr: Strings

The goal of tidyverse is to make easy data analysis by simplifying the data preparation. Tidyverse comes with a new data-type, Tibbles. 

Tibbles can be considered a modern version of data.frame but they differs in some aspects. They do not have rowname and allows users to have colnames with special character (e.g. if colname of x is 'Col 1' then to access to this colnums you can use x$\`Col 1\` to acces to this variables.). It provide a good way also to visualize the data since it directly show data as if you were running the 'head()' function before. It shows you the 10 first rows.

Data.table is also very common when dealing with data and is very fast. Using tibbles can be very time consuming when dealing with large tables.

##  Read/Write data 

<div class = "r">

```{r,echo=T,collapse = TRUE}
# R
library(tidyverse)

covid_papers <- read_csv("data/covid_papers.csv")

covid_papers

```
</div>

Depending on the way string are encoded we may want to precise the type of encoding. (Some well know encoding character format: UTF-8; Unicode; ASCII ..)


we can sepcify this encoding in the read function.
<div class = "r">

```{r,echo=T,collapse = TRUE}
# R
covid_papers <- read_csv("data/covid_papers.csv",locale = locale(encoding = "UTF-8"))
```
</div>
 
Other types of data can be import using other libraries I just show you some examples here without enterring into details that may be helpfull sometimes.

- Excel data

<div class = "r">
```{r,echo=T,collapse = TRUE,eval=F}
# R
library(readxl)

covid_papers <- read_excel("data/covid_papers.xls", sheet = "Feuille1", range = "A1:Z25")
```
</div>

-  SAS, SPSS et Stata data

<div class = "r">

```{r,echo=T,collapse = TRUE,eval=F}
# R
library(haven)

#SAS data
covid_papers <- read_sas("data/covid_papers.sas")
covid_papers <- read_xpt("data/covid_papers.xpt")

#SPSS data
covid_papers <- read_sav("data/covid_papers.sav")
covid_papers <- read_por("data/covid_papers.por")



```
</div>

In order to save data in a specific format we just have to change the 'read' part of the function name by 'write'. Here is an example for csv


<div class = "r">

```{r,echo=T,collapse = TRUE,eval=F}
# R

write_csv(new_data_set,"data/new_data.csv")


```
</div>

## RData

Also R provide a way to store objects in the same file. For this we use RData format, it's very usefull if a project is written totaly in R because you can save the structure of your objects very easily, you can save all type of objects and load it later.
 

<div class = "r">

```{r,echo=T,collapse = TRUE,eval=F}
# R

save(covid_papers,file= 'covid_papers.RData')
load('covid_papers.RData')


```
</div>


## Tibbles and data.tables

https://atrebas.github.io/post/2019-03-03-datatable-dplyr/


### Basic operations

#### Filtering
<div class = "row">
<div class = "col-md-6">
<div class = "r">

```{python,echo = T,collapse = TRUE}
# R using Tibbles


covid_papers[3:4,]
slice(covid_papers, 3:4) # same

covid_papers[-(3:7),]
slice(covid_papers, -(3:7)) # same

filter(covid_papers, V2 > 5)
filter(covid_papers, V4 %in% c("A", "C"))

filter(covid_papers, V1 == 1, V4 == "A")

distinct(covid_papers) # distinct_all(covid_papers)
distinct(covid_papers, across(c(V1, V4))) # returns selected cols

tidyr::drop_na(covid_papers, names(covid_papers))


slice_sample(covid_papers, n = 3)      # n random rows
# sample_n(covid_papers, 3)
slice_sample(covid_papers, prop = 0.5) # fraction of rows
# sample_frac(covid_papers, 0.5)
covid_papers %>% slice_max(V1, n = 1)

filter(covid_papers, grepl("^B", V4))
filter(covid_papers, dplyr::between(V2, 3, 5))
filter(covid_papers, V2 > 3 & V2 < 5)
filter(covid_papers, V2 >= -1:1 & V2 <= 1:3)
```

</div>
</div>
<div class = "col-md-6">
<div class = "r">

```{r,echo=T,collapse = TRUE}
# R using data.table

DT[3:4,]
DT[3:4] # same

DT[!3:7,]
DT[-(3:7)] # same

DT[V2 > 5]
DT[V4 %chin% c("A", "C")] # fast %in% for character

DT[V1 == 1 & V4 == "A"]

unique(DT)
unique(DT, by = c("V1", "V4")) # returns all cols

na.omit(DT, cols = 1:4)  # fast S3 method with cols argument

DT[sample(.N, 3)] # .N = nb of rows in DT
DT[sample(.N, .N / 2)]
DT[frankv(-V1, ties.method = "dense") < 2] 

DT[V4 %like% "^B"]
DT[V2 %between% c(3, 5)]
DT[data.table::between(V2, 3, 5, incbounds = FALSE)]
DT[V2 %inrange% list(-1:1, 1:3)] # see also ?inrange

```

</div>
</div>
</div>

# top_n(DF, 1, V1)
On the other hand, data.table also provides convenience functions to filter rows based on a regular expression or to find values lying in one (or several) interval(s).

Below, we will see that data.table has two optimized mechanisms to filter rows efficiently (keys and indices).


Sort rows
Sort rows by column
DT[order(V3)]  # see also setorder
arrange(DF, V3)
Sort rows in decreasing order
DT[order(-V3)]
arrange(DF, desc(V3))
Sort rows based on several columns
DT[order(V1, -V2)]
arrange(DF, V1, desc(V2))

Select columns
Select one column using an index (not recommended)
DT[[3]] # returns a vector
DT[, 3]  # returns a data.table
DF[[3]] # returns a vector
DF[3]   # returns a tibble
Select one column using column name
DT[, list(V2)] # returns a data.table
DT[, .(V2)]    # returns a data.table
# . is an alias for list
DT[, "V2"]     # returns a data.table
DT[, V2]       # returns a vector
DT[["V2"]]     # returns a vector
select(DF, V2) # returns a tibble
pull(DF, V2, name = V4)   # returns a (named) vector
DF[, "V2"]        # returns a tibble
DF[["V2"]]        # returns a vector
Select several columns
DT[, .(V2, V3, V4)]
DT[, list(V2, V3, V4)]
DT[, V2:V4] # select columns between V2 and V4
select(DF, V2, V3, V4)
select(DF, V2:V4) # select columns between V2 and V4
Exclude columns
DT[, !c("V2", "V3")]
select(DF, -V2, -V3)
Select/Exclude columns using a character vector
cols <- c("V2", "V3")
DT[, ..cols] # .. prefix means 'one-level up'
DT[, !..cols] # or DT[, -..cols]
cols <- c("V2", "V3")
select(DF, !!cols) # unquoting
select(DF, -!!cols)
Other selections
As for row filtering, dplyr includes helper functions to select column. With data.table, a possible solution is to first retrieve the column names (e.g. using a regular expression), then select these columns. Another way (using patterns()) is presented in a next section.
cols <- paste0("V", 1:2)
cols <- union("V4", names(DT))
cols <- grep("V",   names(DT))
cols <- grep("3$",  names(DT))
cols <- grep(".2",  names(DT))
cols <- grep("^V1|X$",  names(DT))
cols <- grep("^(?!V2)", names(DT), perl = TRUE)
DT[, ..cols]
select(DF, num_range("V", 1:2))
select(DF, V4, everything()) # reorder columns
select(DF, contains("V"))
select(DF, ends_with("3"))
select(DF, matches(".2"))
select(DF, one_of(c("V1", "X")))
select(DF, -starts_with("V2"))
# remove variables using "-" prior to function

Summarise data
Summarise one column
DT[, sum(V1)]    # returns a vector
DT[, .(sum(V1))] # returns a data.table
DT[, .(sumV1 = sum(V1))] # returns a data.table
summarise(DF, sum(V1)) # returns a tibble
summarise(DF, sumV1 = sum(V1)) # returns a tibble
Summarise several columns
DT[, .(sum(V1), sd(V3))]
summarise(DF, sum(V1), sd(V3))
Summarise several columns and assign column names
DT[, .(sumv1 = sum(V1),
       sdv3  = sd(V3))]
DF %>%
  summarise(sumv1 = sum(V1),
            sdv3  = sd(V3))
Summarise a subset of rows
DT[1:4, sum(V1)]
DF %>%
  slice(1:4) %>%
  summarise(sum(V1))
dplyr helper functions for summarise() (or summarize()) include first(), last(), n(), nth(), and n_distinct(). The data.table package also include first(), last(), and uniqueN().
DT[, data.table::first(V3)]
DT[, data.table::last(V3)]
DT[5, V3]
DT[, uniqueN(V4)]
uniqueN(DT)
summarise(DF, dplyr::first(V3))
summarise(DF, dplyr::last(V3))
summarise(DF, nth(V3, 5))
summarise(DF, n_distinct(V4))
n_distinct(DF)

Add/update/delete columns
In the following commands, with data.table, columns are modified by reference using the column assignment symbol := (no copy performed) and the results are returned invisibly. With dplyr, we have to assign the results.

Modify a column
DT[, V1 := V1^2]
DT
DF <- DF %>% mutate(V1 = V1^2)
DF
Add one column
DT[, v5 := log(V1)][] # adding [] prints the result
DF <- mutate(DF, v5 = log(V1))
# see ?mutate for options (.keep, .before, ...)
Add several columns
DT[, c("v6", "v7") := .(sqrt(V1), "X")]

DT[, ':='(v6 = sqrt(V1),
          v7 = "X")]     # same, functional form
DF <- mutate(DF, v6 = sqrt(V1), v7 = "X")
Create one column and remove the others
DT[, .(v8 = V3 + 1)]
transmute(DF, v8 = V3 + 1)
Remove one column
DT[, v5 := NULL]
DF <- select(DF, -v5)
Remove several columns
DT[, c("v6", "v7") := NULL]
DF <- select(DF, -v6, -v7)
Remove columns using a vector of colnames
cols <- c("V3")
DT[, (cols) := NULL] # ! not DT[, cols := NULL]
cols <- c("V3")
DF <- select(DF, -one_of(cols))
Replace values for rows matching a condition
DT[V2 < 4, V2 := 0L]
DT
DF <- mutate(DF, V2 = base::replace(V2, V2 < 4, 0L))
DF

by
The dplyr::group_by() function and the corresponding by and keyby statements in data.table allow to run manipulate each group of observations and combine the results. The sole difference between by and keyby is that keyby orders the results and creates a key that will allow faster subsetting (cf. the indexing and keys section). Below, we arbitrary use one or the other.
group_by() takes an existing tibble and converts it into a grouped tibble where operations will always be performed “by group”. Using ungroup() removes grouping. With data.table, by is always used on the fly.
Note that it is possible to reorder the arguments in data.table: DT[i, j, by] <=> DT[i, by, j]. This is done below to better highlight the similarity with dplyr.

By group
# one-liner:
DT[, .(sumV2 = sum(V2)), by = "V4"]
# reordered and indented:
DT[, by = V4,
     .(sumV2 = sum(V2))]
# 
DF %>%
  group_by(V4) %>%
  summarise(sumV2 = sum(V2))
# ungrouped output
By several groups
DT[, keyby = .(V4, V1),
     .(sumV2 = sum(V2))]
DF %>%
  group_by(V4, V1) %>%
  summarise(sumV2 = sum(V2))
# output grouped by V4
Calling function in by
DT[, by = tolower(V4),
     .(sumV1 = sum(V1))]
DF %>%
  group_by(tolower(V4)) %>%
  summarise(sumV1 = sum(V1))
Assigning column name in by
DT[, keyby = .(abc = tolower(V4)),
     .(sumV1 = sum(V1))]
DF %>%
  group_by(abc = tolower(V4)) %>%
  summarise(sumV1 = sum(V1))
Using a condition in by
DT[, keyby = V4 == "A",
     sum(V1)]
DF %>%
  group_by(V4 == "A") %>%
  summarise(sum(V1))
By on a subset of rows
DT[1:5,                # i
   .(sumV1 = sum(V1)), # j
   by = V4]            # by
## complete DT[i, j, by] expression!
DF %>%
  slice(1:5) %>%
  group_by(V4) %>%
  summarise(sumV1 = sum(V1))
Count number of observations for each group
DT[, .N, by = V4]
count(DF, V4)
DF %>%
  group_by(V4) %>%
  tally()
DF %>%
  group_by(V4) %>%
  summarise(n())
DF %>%
  group_by(V4) %>%
  group_size() # returns a vector
Add a column with number of observations for each group
DT[, n := .N, by = V1][]
DT[, n := NULL] # rm column for consistency
add_count(DF, V1)
DF %>%
  group_by(V1) %>%
  add_tally()
Retrieve the first/last/nth observation for each group
DT[, data.table::first(V2), by = V4]
DT[, data.table::last(V2), by = V4]
DT[, V2[2], by = V4]
DF %>%
  group_by(V4) %>%
  summarise(dplyr::first(V2))
DF %>%
  group_by(V4) %>%
  summarise(dplyr::last(V2))
DF %>%
  group_by(V4) %>%
  summarise(dplyr::nth(V2, 2))





# Pandas (Python)