---
title: "Efficient Programming"
---

# Parallel computing



# Python Generators

Generator usages in Python is a simple way of creating iterators. The goal of this kind of function is to return an object for which we can iterate over it. The difference in terms of syntax hold in the fact that we will the statement 'yield' instead of 'return'. In comparaison to 'return', using 'yield' will pause the function and the control of that generator will be trasnfered to the object that call this generator.  
Generators are very useful when we deal with objects which can be too heavy to store all the information in the memory.
As a generators is an iterator, it will load in the RAM only the iteration that it is reading, meaning that we can have no size limit if we want to iterate over an object that is to heavy.
This first example is made with a txt file with 1000 rows. We will see how RAM is used behind our machine to understand how it can be relevant to use generators. 


<div class = "row">
<div class = "col-md-6">
<div class = "python">
```{python,echo = T,collapse = TRUE}
# Python 
import os
import psutil
import re
process = psutil.Process(os.getpid())

t = time.time()
r1 = process.memory_info().rss 
def read_file_to_lower():
  with open("data/text.txt", "r") as txt:
    txt_list = txt.read().split('\n')
    txt_list_low = [re.sub(' ','',row.lower()) for row in txt_list] # re.sub here is used to modify each ' ' by nothing.
  return txt_list_low

txt_clean = read_file_to_lower()

process.memory_info().rss - r1 # in bytes
time.time() - t

type(txt_clean)

```

</div>
</div>

<div class = "col-md-6">
<div class = "python">

```{python,echo=T,collapse = TRUE}
# Python

process = psutil.Process(os.getpid())

t = time.time()
r1 = process.memory_info().rss 

def read_to_lower():
  with open("data/text.txt", "r") as txt:
    txt_line = txt.readline()
    while txt_line:
      txt_line = txt.readline()
      yield re.sub(' ','',txt_line.lower())


memory_friendly_txt_clean = read_to_lower()
txt_clean = [line_clean for line_clean in memory_friendly_txt_clean]

process.memory_info().rss - r1 # in bytes
time.time() - t


type(memory_friendly_txt_clean)



```

</div>
</div>
</div>


Note how the memory used during the calculation is very different while the time spend does not really change. 

<p>&nbsp;</p>


# Sparse Matrix

When dealing with large array that are sparse (lot of element equalt to 0), it is inneficient to store this object as a dense matrix. Large matrix are sometimes difficult to store in the memory because they are weighty, when they dealing with sparse we can store it and do calculation with them in a very efficient way using the 'Compressed Sparse Column' (CSC) format. See how it change the weight of the matrix when changing the format to sparse matrix .

<div class = "row">
<div class = "col-md-6">
<div class = "python">

```{python}
# Python 
 
#from scipy.sparse import csr_matrix
#
#X = np.zeros((10000,10000))
#
#idx = list(np.ndindex(X.shape))[np.random.randint(1,10000**2,1000)]
#
#X[idx] = 1
```

```{python}
# Python 

```

</div>
</div>
<div class = "col-md-6">
<div class = "r">

```{r, collapse = TRUE}
# R
library(Matrix)

mat = matrix(0,10000,10000)
idx = round(runif(1000,1,10000**2))

mat[idx] = 1

print(object.size(mat),units = 'auto')

sparse_mat = Matrix(mat,sparse = T)
print(object.size(sparse_mat),units = 'auto')
```

```{r, collapse = TRUE}
# R

mat = matrix(0,10000,10000)
idx = round(runif(100000,1,10000**2))

mat[idx] = 1

print(object.size(mat),units = 'auto')

sparse_mat = Matrix(mat,sparse = T)
print(object.size(sparse_mat),units = 'auto')
```

</div>
</div>
</div>
